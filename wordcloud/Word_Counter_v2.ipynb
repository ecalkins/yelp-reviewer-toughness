{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:05:29.221728Z",
     "start_time": "2018-12-07T05:05:29.202753Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from textblob import TextBlob as tb\n",
    "from cust_stop_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:09.865464Z",
     "start_time": "2018-12-07T05:00:08.726460Z"
    }
   },
   "outputs": [],
   "source": [
    "input_json = \"../df_by_usr.json\"\n",
    "with open(input_json, 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = list(map(json.loads, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:09.935519Z",
     "start_time": "2018-12-07T05:00:09.865464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_star_delta</th>\n",
       "      <th>reviewer_label</th>\n",
       "      <th>text_agg</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.318182</td>\n",
       "      <td>med</td>\n",
       "      <td>ummm star ratings yelp point come sandwich pla...</td>\n",
       "      <td>--3WaS23LcIXtxyFULJHTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.947368</td>\n",
       "      <td>hard</td>\n",
       "      <td>opinion restaurant best food phoenix tastes gr...</td>\n",
       "      <td>--4rAAfZnEIAKJE80aIiYg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>med</td>\n",
       "      <td>right world going gawd awful hooters vegas get...</td>\n",
       "      <td>--CIuK7sUpaNzalLAlHJKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>easy</td>\n",
       "      <td>best buffets price quality went saturday night...</td>\n",
       "      <td>--HCoE1ghaAlcaAfshICgw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166667</td>\n",
       "      <td>med</td>\n",
       "      <td>great pizza pasta just quality pizza definitel...</td>\n",
       "      <td>--NIc98RMssgy0mSZL3vpA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_star_delta reviewer_label  \\\n",
       "0       -0.318182            med   \n",
       "1       -0.947368           hard   \n",
       "2        0.333333            med   \n",
       "3        0.900000           easy   \n",
       "4       -0.166667            med   \n",
       "\n",
       "                                            text_agg                 user_id  \n",
       "0  ummm star ratings yelp point come sandwich pla...  --3WaS23LcIXtxyFULJHTA  \n",
       "1  opinion restaurant best food phoenix tastes gr...  --4rAAfZnEIAKJE80aIiYg  \n",
       "2  right world going gawd awful hooters vegas get...  --CIuK7sUpaNzalLAlHJKA  \n",
       "3  best buffets price quality went saturday night...  --HCoE1ghaAlcaAfshICgw  \n",
       "4  great pizza pasta just quality pizza definitel...  --NIc98RMssgy0mSZL3vpA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:09.943499Z",
     "start_time": "2018-12-07T05:00:09.937513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35051, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:10.118306Z",
     "start_time": "2018-12-07T05:00:10.107329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5910"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_easy = list(df.loc[df['reviewer_label'] == 'easy'][\"text_agg\"])\n",
    "len(df_easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:11.541936Z",
     "start_time": "2018-12-07T05:00:11.533999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy', 'hard', 'med'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewer_label_list = set(df['reviewer_label'])\n",
    "reviewer_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:12.155677Z",
     "start_time": "2018-12-07T05:00:12.070741Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_text_agg = dict()\n",
    "for label in reviewer_label_list:\n",
    "    temp_text_agg = list(df.loc[df['reviewer_label'] == label][\"text_agg\"])\n",
    "    temp_text_agg = [w.replace(\"\\n\", \" \") for w in temp_text_agg]\n",
    "    temp_text_agg = [w.replace(\"\\r\", \" \") for w in temp_text_agg]\n",
    "    dict_text_agg[label] = temp_text_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:00:27.859628Z",
     "start_time": "2018-12-07T05:00:12.992529Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Spark Setup\n",
    "app_name = \"most_common_word_review\"\n",
    "conf = SparkConf().setAppName(app_name)\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:05:40.673116Z",
     "start_time": "2018-12-07T05:05:40.664131Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and return a non-unique list of tokenized words\n",
    "    found in the text. Normalize to lowercase, strip punctuation,\n",
    "    remove stop words, drop words of length < 3, strip digits.\n",
    "    \"\"\"\n",
    "    text = text.lower() # get lower case\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)  # remove all punctuation + numbers\n",
    "    nopunct = re.sub(r\"\\s+\", ' ', nopunct) # replace multiple spaces with one space\n",
    "    words = nltk.word_tokenize(nopunct)        \n",
    "    words = [w for w in words if len(w) > 2] # drop words of length < 3\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    return words\n",
    "\n",
    "# Customized version of tokenize with spell check option\n",
    "def norm_correct(text, spell):\n",
    "    punct = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\{\\\\|\\\\}\\\\~0-9\\\\r\\\\t\\\\n]'\n",
    "    text = text.lower()\n",
    "    punct_regex = re.compile(punct)\n",
    "    not_regex = re.compile(\"(n\\\\'t)\")\n",
    "    text = not_regex.sub(' not', text)\n",
    "    words = punct_regex.sub(\" \", text).split()\n",
    "    \n",
    "    if spell:\n",
    "        words = [str(tb(w).correct()) for w in words if len(w) > 2 if w not in stop_words]\n",
    "    else:\n",
    "        words = [w for w in words if len(w) > 2 if w not in stop_words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def most_common_n(filename, n, spell):\n",
    "    rdd = sc.parallelize(filename, 8)\n",
    "    rdd_listed = rdd.flatMap(lambda x: tokenize(x))\n",
    "    ctr = Counter(rdd_listed.collect())\n",
    "    most_common_list = ctr.most_common(n)\n",
    "    \n",
    "    return most_common_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:06:28.418921Z",
     "start_time": "2018-12-07T05:05:41.929489Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "most_common_n_dict = {}\n",
    "for label in reviewer_label_list:\n",
    "    most_common_n_dict[label] = most_common_n(dict_text_agg[label], n, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:06:35.138961Z",
     "start_time": "2018-12-07T05:06:35.132958Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 51258),\n",
       " ('great', 44206),\n",
       " ('place', 43453),\n",
       " ('good', 42891),\n",
       " ('service', 27476),\n",
       " ('like', 21951),\n",
       " ('time', 21330),\n",
       " ('just', 20769),\n",
       " ('love', 18303),\n",
       " ('really', 17906),\n",
       " ('delicious', 16948),\n",
       " ('best', 15713),\n",
       " ('nice', 14078),\n",
       " ('chicken', 13986),\n",
       " ('friendly', 13954),\n",
       " ('amazing', 13815),\n",
       " ('restaurant', 13343),\n",
       " ('try', 13082),\n",
       " ('did', 12890),\n",
       " ('ordered', 12650),\n",
       " ('staff', 12491),\n",
       " ('got', 12428),\n",
       " ('order', 12282),\n",
       " ('menu', 11935),\n",
       " ('definitely', 11607),\n",
       " ('little', 10660),\n",
       " ('fresh', 10599),\n",
       " ('pizza', 10279),\n",
       " ('come', 9984),\n",
       " ('came', 9384),\n",
       " ('eat', 8635),\n",
       " ('bar', 8483),\n",
       " ('wait', 8411),\n",
       " ('lunch', 8361),\n",
       " ('went', 8165),\n",
       " ('awesome', 8048),\n",
       " ('cheese', 7995),\n",
       " ('make', 7937),\n",
       " ('favorite', 7925),\n",
       " ('people', 7846),\n",
       " ('pretty', 7839),\n",
       " ('recommend', 7583),\n",
       " ('dinner', 7448),\n",
       " ('night', 7443),\n",
       " ('salad', 7409),\n",
       " ('experience', 7309),\n",
       " ('sauce', 7278),\n",
       " ('right', 6984),\n",
       " ('excellent', 6899),\n",
       " ('meal', 6761)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_n_dict['easy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:06:43.085552Z",
     "start_time": "2018-12-07T05:06:42.339579Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T05:06:46.185181Z",
     "start_time": "2018-12-07T05:06:46.172216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the list\n",
    "filename = 'most_common_n_dict'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(most_common_n_dict, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
